{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6eebe5-1dd4-46e9-a053-be8ccacec07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def extract_frames(video_path, output_dir, fps=5):\n",
    "    \"\"\"\n",
    "    Extract frames from a video and save them as images.\n",
    "    Args:\n",
    "    - video_path (str): Path to the video file.\n",
    "    - output_dir (str): Directory to save the frames.\n",
    "    - fps (int): Number of frames per second to extract.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    # os.makedirs(output_dir) \n",
    "    \n",
    "    # cap = cv2.VideoCapture(video_path)\n",
    "    # video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # interval = int(video_fps / fps)\n",
    "    \n",
    "    # frame_count = 0\n",
    "    # while cap.isOpened():\n",
    "    #     ret, frame = cap.read()\n",
    "    #     if not ret:\n",
    "    #         break\n",
    "    #     if frame_count % interval == 0:\n",
    "    #         frame_filename = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "    #         cv2.imwrite(frame_filename, frame)\n",
    "    #     frame_count += 1\n",
    "    #     # if frame_count == 10:\n",
    "    #     #     break\n",
    "        \n",
    "    # cap.release()\n",
    "\n",
    "# Example usage\n",
    "# extract_frames('path_to_video.mp4', 'output_frames/', fps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fde0c9-6779-4603-b3cf-21f5107ae373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking folder: ./ucf_sports_actions/ucf action/Diving-Side\n",
      "\n",
      "./ucf_sports_actions/ucf action/Diving-Side/007/4475-6_70099.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/001/2538-5_70133.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/006/4475-2_70045.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/003/2538-12_70246.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/004/2538-16_70032.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/005/4475-1_70541.avi\n",
      "./ucf_sports_actions/ucf action/Diving-Side/002/2538-11_70015.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Golf-Swing-Back\n",
      "\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Back/001/3283-8_700741.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Back/003/7608-12_70275.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Back/004/7616-7_70270.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Back/005/RF1-13903_70070.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Back/002/3283-8_701201.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Golf-Swing-Front\n",
      "\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/007/RF1-13588_70046.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/008/RF1-13678_70045.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/001/7603-4_70159.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/006/RF1-13428_70288.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/003/RF1-13157_70040.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/004/RF1-13206_70024.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/005/RF1-13209_70050.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Front/002/7608-9_70(2)151.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Golf-Swing-Side\n",
      "\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Side/001/RF1-13207_7015.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Side/003/7608-5_70308.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Side/004/7608-5_70039.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Side/005/7606-2_700810.avi\n",
      "./ucf_sports_actions/ucf action/Golf-Swing-Side/002/RF1-11456_70034.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Kicking-Front\n",
      "\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/007/6063-21_70056.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/009/6729-10_70314.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/008/6351-6_70000.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/001/778-62_l146.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/006/5117-8_70113.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/010/6731-2_70017.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/003/3833-27_70006.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/004/3937-9_70105.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/005/3949-12_70207.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Front/002/1084-44_l865.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Kicking-Side\n",
      "\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/007/6351-1_70011.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/009/pstch3_clp21_0088_l105.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/008/pstch3_clp16_0079_l050.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/001/3833-15_70577.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/006/6063-20_70333.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/010/RF1-16941_70021.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/003/3833-41_70187.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/004/5117-8_70350.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/005/5863-29_70025.avi\n",
      "./ucf_sports_actions/ucf action/Kicking-Side/002/3833-40_70336.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Lifting\n",
      "\n",
      "./ucf_sports_actions/ucf action/Lifting/001/3528-8_70514.avi\n",
      "./ucf_sports_actions/ucf action/Lifting/006/3528-10_70424.avi\n",
      "./ucf_sports_actions/ucf action/Lifting/003/2502-3_70368.avi\n",
      "./ucf_sports_actions/ucf action/Lifting/004/3528-6_70(2)268.avi\n",
      "./ucf_sports_actions/ucf action/Lifting/005/3528-6_70270.avi\n",
      "./ucf_sports_actions/ucf action/Lifting/002/2502-2_70340.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Riding-Horse\n",
      "\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/012/7467-18_70103.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/007/6029-1_70001.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/009/6326-9_70170.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/008/6029-1_70143.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/001/4456-16_700040.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/006/6018-29_70000.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/011/1098-6_70000.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/010/RF1-12001_70063.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/003/4456-16_700273.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/004/4456-16_700406.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/005/4456-16_700516.avi\n",
      "./ucf_sports_actions/ucf action/Riding-Horse/002/4456-16_700165.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Run-Side\n",
      "\n",
      "./ucf_sports_actions/ucf action/Run-Side/012/7603-3_70195.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/013/5020-1_70062.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/007/6065-8_70110.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/009/3687-17_70245.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/008/7850-5_70090.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/001/2670-5_70111.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/006/5238-17_701141.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/011/5117-8_70157.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/010/5373-10_70026.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/003/5238-17_700641.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/004/5238-17_700950.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/005/5238-17_701581.avi\n",
      "./ucf_sports_actions/ucf action/Run-Side/002/5238-17_700000.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/SkateBoarding-Front\n",
      "\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/012/1058-22003.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/007/860-37150.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/009/947-58108.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/008/860-38064.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/001/708-75070.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/006/860-2729.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/011/947-70454.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/010/947-70005.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/003/711-66044.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/004/761-39000.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/005/860-2001.avi\n",
      "./ucf_sports_actions/ucf action/SkateBoarding-Front/002/708-77009.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Swing-Bench\n",
      "\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/015/2527-12_70411.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/012/2527-12_70186.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/013/2527-12_70297.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/014/2527-12_70360.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/007/2527-5_70114.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/009/2527-9_70087.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/008/2527-9_70018.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/001/669-60084.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/006/2527-5_70020.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/020/4379-9_70018.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/018/2527-12_70574.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/011/2527-12_70137.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/016/2527-12_70461.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/017/2527-12_70526.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/010/2527-9_70267.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/019/2527-12_70641.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/003/669-60220.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/004/669-67070.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/005/669-67178.avi\n",
      "./ucf_sports_actions/ucf action/Swing-Bench/002/669-60176.avi\n",
      "Checking folder: ./ucf_sports_actions/ucf action/Walk-Front\n",
      "\n",
      "./ucf_sports_actions/ucf action/Walk-Front/015/RF1-18566_700411.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/012/RF1-18156_70301.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/013/RF1-18524_70031.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/014/RF1-18526_70364.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/022/7608-3_70626.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/007/RF1-14377_70025.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/009/RF1-15341_70050.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/008/RF1-15295_70060.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/001/3206-12_70000.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/006/RF1-13902_70016.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/020/RF1-13204_70095.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/018/RF1-18598_70530.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/011/RF1-18085_70010.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/016/RF1-18566_700560.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/017/RF1-18598_70075.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/010/RF1-18075_70140.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/019/RF1-18602_70140.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/021/RF1-13205_70100.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/003/RF1-10578_70285.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/004/RF1-10799_70080.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/005/RF1-11529_70033.avi\n",
      "./ucf_sports_actions/ucf action/Walk-Front/002/5561-7_70102.avi\n"
     ]
    }
   ],
   "source": [
    "def find_videos_and_run_extract_frames(base_path, label_map):\n",
    "    for class_label, class_name in label_map.items():\n",
    "        class_folder = f'{base_path}/{class_name}'\n",
    "        print(f\"Checking folder: {class_folder}\\n\")  # Print the folder being checked\n",
    "        \n",
    "        if not os.path.exists(class_folder):\n",
    "            print(f\"Folder does not exist: {class_folder}\\n\")  # Print if the folder doesn't exist\n",
    "            continue\n",
    "            \n",
    "        # Loop through each subfolder\n",
    "        subfolders = os.listdir(class_folder)\n",
    "        \n",
    "        if '.DS_Store' in subfolders:\n",
    "            subfolders.remove('.DS_Store')\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            # print(f'{class_folder}/{subfolder}')\n",
    "            for image_file in os.listdir(f'{class_folder}/{subfolder}'):\n",
    "                if '.avi' in f'{class_folder}/{subfolder}/{image_file}':\n",
    "                    print(f'{class_folder}/{subfolder}/{image_file}')\n",
    "                    extract_frames(f'{class_folder}/{subfolder}/{image_file}', f'{class_folder}/{subfolder}/output_frames/', fps=9)\n",
    "\n",
    "# Define your label map based on your class names\n",
    "label_map = {\n",
    "    0: \"Diving-Side\", 1: \"Golf-Swing-Back\", 2: \"Golf-Swing-Front\", \n",
    "    3: \"Golf-Swing-Side\", 4: \"Kicking-Front\", 5: \"Kicking-Side\",\n",
    "    6: \"Lifting\", 7: \"Riding-Horse\", 8: \"Run-Side\", \n",
    "    9: \"SkateBoarding-Front\", 10: \"Swing-Bench\", 11: \"Walk-Front\"\n",
    "}\n",
    "\n",
    "# Load image data\n",
    "base_path = \"./ucf_sports_actions/ucf action\"\n",
    "find_videos_and_run_extract_frames(base_path, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c737f-a7e7-47e7-8029-5c059b45cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ActionRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ActionRecognitionModel, self).__init__()\n",
    "        \n",
    "        # Pretrained 2D CNN (ResNet) for feature extraction\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "        # 3D Convolution Layer\n",
    "        self.conv3d = nn.Conv3d(1, 64, kernel_size=(3, 3, 3), stride=1, padding=1)\n",
    "        \n",
    "        # LSTM for Temporal Dynamics\n",
    "        self.lstm = nn.LSTM(2048, 512, batch_first=True)\n",
    "        \n",
    "        # Fully Connected Layer for classification\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch_size, time_steps, c, h, w = x.size()\n",
    "        # cnn_out = []\n",
    "        \n",
    "        # # Apply CNN to each frame\n",
    "        # for t in range(time_steps):\n",
    "        #     frame_features = self.feature_extractor(x[:, t, :, :, :])\n",
    "        #     cnn_out.append(frame_features)\n",
    "        \n",
    "        # cnn_out = torch.stack(cnn_out, dim=1)  # Shape: (batch_size, time_steps, 2048)\n",
    "        # cnn_out = cnn_out.view(batch_size, time_steps, -1)  # Flatten\n",
    "        \n",
    "        # # LSTM for sequence processing\n",
    "        # lstm_out, _ = self.lstm(cnn_out)\n",
    "        \n",
    "        # # Classification layer\n",
    "        # out = self.fc(lstm_out[:, -1, :])  # Take the output from the last time step\n",
    "        # return out\n",
    "        batch_size, c, h, w = x.size()  # Expecting 4 dimensions from DataLoader\n",
    "        x = x.unsqueeze(1)  # Add time step dimension, making it (batch_size, time_steps, c, h, w)\n",
    "        batch_size, time_steps, c, h, w = x.size()\n",
    "        \n",
    "        cnn_out = []\n",
    "        \n",
    "        # Apply CNN to each frame\n",
    "        for t in range(time_steps):\n",
    "            frame_features = self.feature_extractor(x[:, t, :, :, :])  # Output shape: (batch_size, 2048, H', W')\n",
    "            \n",
    "            # Apply adaptive average pooling to reduce (2048, H', W') to (2048, 1, 1)\n",
    "            frame_features = torch.nn.functional.adaptive_avg_pool2d(frame_features, (1, 1))\n",
    "            \n",
    "            # Flatten to get (batch_size, 2048)\n",
    "            frame_features = frame_features.view(batch_size, 2048)\n",
    "            cnn_out.append(frame_features)\n",
    "        \n",
    "        cnn_out = torch.stack(cnn_out, dim=1)  # Shape: (batch_size, time_steps, 2048)\n",
    "        \n",
    "        # LSTM for sequence processing\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        \n",
    "        # Classification layer\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the output from the last time step\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = ActionRecognitionModel(num_classes=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0074b-be6d-4639-855e-9d87bc673f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device ===========> {device}')\n",
    "# Move the model to the appropriate device\n",
    "\n",
    "# Custom function to pad images to a target size\n",
    "def pad_tensor(image, target_size):\n",
    "    # Convert image to tensor first if not already done\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    \n",
    "    # Padding: pad (width, height) to match the target size\n",
    "    padded_tensor = F.pad(tensor, \n",
    "                          (0, target_size[2] - tensor.size(2),  # pad width\n",
    "                           0, target_size[1] - tensor.size(1)))  # pad height\n",
    "    return padded_tensor\n",
    "\n",
    "# Custom transform to resize or pad images to the target size\n",
    "class ResizeOrPadTransform:\n",
    "    def __init__(self, target_size):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        # Pad image to target size\n",
    "        return pad_tensor(image, self.target_size)\n",
    "\n",
    "# Set your desired target size (C, H, W) - example target size (3, 404, 720)\n",
    "target_size = (3, 404, 720)\n",
    "\n",
    "# Use the custom transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    ResizeOrPadTransform(target_size)  # Apply padding to match target size\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "train_dataset = ImageFolder('./ucf_sports_actions/ucf action/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Get the class names and the number of classes\n",
    "class_names = train_dataset.classes  # List of class names\n",
    "num_classes = len(class_names)  # Number of classes\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d9003-c3b4-421f-b684-47ff0aa8e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    return f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "# Example evaluation\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "f1 = evaluate_model(model, test_loader)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937c0e5-fb42-430b-8c50-aead9e074472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def apply_pruning(model):\n",
    "    \"\"\"\n",
    "    Apply pruning to the model. \n",
    "    This will prune the weights of the layers to reduce memory and computation.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        # Prune the linear and convolutional layers\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            prune.l1_unstructured(module, name='weight', amount=0.3)  # Prune 30% of weights\n",
    "            prune.remove(module, 'weight')  # Remove the mask and make pruning permanent\n",
    "\n",
    "# Example usage:\n",
    "apply_pruning(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedeace-3efa-4d48-b723-95221fca5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static quantization\n",
    "def apply_quantization(model):\n",
    "    \"\"\"\n",
    "    Apply static quantization to the model to reduce its size and speed up inference.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Fuse Conv + BatchNorm + ReLU layers for better quantization performance\n",
    "    fused_model = torch.quantization.fuse_modules(model, [['conv3d', 'bn', 'relu']])\n",
    "\n",
    "    # Apply quantization-aware training\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "    torch.quantization.prepare(fused_model, inplace=True)\n",
    "\n",
    "    # Calibrate with a few batches (optional, improves performance)\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in train_loader:\n",
    "            fused_model(inputs)\n",
    "            break  # One batch should be enough for calibration\n",
    "\n",
    "    # Convert to quantized model\n",
    "    quantized_model = torch.quantization.convert(fused_model, inplace=True)\n",
    "    return quantized_model\n",
    "\n",
    "# Example usage:\n",
    "quantized_model = apply_quantization(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff06376-79ba-4bcc-9b03-bc9a33358e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_model.state_dict(), 'optimized_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93027d-1c7e-495d-ab84-d649df8ac3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19980e29-1213-4f88-a647-1108c1aae918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "import torch\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the optimized model\n",
    "model = ActionRecognitionModel(num_classes=10)\n",
    "model.load_state_dict(torch.load('optimized_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Transform for frame preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Preprocess frame\n",
    "        frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frame = transform(frame).unsqueeze(0)\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return torch.cat(frames)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return \"No file uploaded\", 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "    video_path = './uploads/' + file.filename\n",
    "    file.save(video_path)\n",
    "    \n",
    "    # Process video and predict actions\n",
    "    video_frames = process_video(video_path)\n",
    "    with torch.no_grad():\n",
    "        output = model(video_frames)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    return f\"Predicted Action Class: {predicted_class}\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6838a-4341-49d5-8094-9d6e8993613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Sports Action Recognition</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Upload a Sports Video</h1>\n",
    "    <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "        <input type=\"file\" name=\"file\">\n",
    "        <button type=\"submit\">Predict Action</button>\n",
    "    </form>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609608e-f8bc-4714-b485-4361903c318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "python app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
